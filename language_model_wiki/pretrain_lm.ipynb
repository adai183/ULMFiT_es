{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from sampled_sm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lm(dir_path, cuda_id, cl=1, bs=64, backwards=False, lr=3e-4, sampled=True,\n",
    "             pretrain_id=''):\n",
    "    print(f'dir_path {dir_path}; cuda_id {cuda_id}; cl {cl}; bs {bs}; '\n",
    "          f'backwards {backwards}; lr {lr}; sampled {sampled}; '\n",
    "          f'pretrain_id {pretrain_id}')\n",
    "    if not hasattr(torch._C, '_cuda_setDevice'):\n",
    "        print('CUDA not available. Setting device=-1.')\n",
    "        cuda_id = -1\n",
    "    torch.cuda.set_device(cuda_id)\n",
    "    PRE  = 'bwd_' if backwards else 'fwd_'\n",
    "    IDS = 'ids'\n",
    "    p = Path(dir_path)\n",
    "    assert p.exists(), f'Error: {p} does not exist.'\n",
    "    bptt=70\n",
    "    em_sz,nh,nl = 400,1150,3\n",
    "    opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "\n",
    "    if backwards:\n",
    "        trn_lm = np.load(p / f'tmp/trn_{IDS}_bwd.npy')\n",
    "        val_lm = np.load(p / f'tmp/val_{IDS}_bwd.npy')\n",
    "    else:\n",
    "        trn_lm = np.load(p / f'tmp/trn_{IDS}.npy')\n",
    "        val_lm = np.load(p / f'tmp/val_{IDS}.npy')\n",
    "    trn_lm = np.concatenate(trn_lm)\n",
    "    val_lm = np.concatenate(val_lm)\n",
    "\n",
    "    itos = pickle.load(open(p / 'tmp/itos.pkl', 'rb'))\n",
    "    vs = len(itos)\n",
    "\n",
    "    trn_dl = LanguageModelLoader(trn_lm, bs, bptt)\n",
    "    val_dl = LanguageModelLoader(val_lm, bs//5 if sampled else bs, bptt)\n",
    "    md = LanguageModelData(p, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)\n",
    "\n",
    "    tprs = get_prs(trn_lm, vs)\n",
    "    drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.5\n",
    "    learner,crit = get_learner(drops, 15000, sampled, md, em_sz, nh, nl, opt_fn, tprs)\n",
    "    wd=1e-7\n",
    "    learner.metrics = [accuracy]\n",
    "\n",
    "    lrs = np.array([lr/6,lr/3,lr,lr])\n",
    "    #lrs=lr\n",
    "\n",
    "    learner.fit(lrs, 1, wds=wd, use_clr=(32,10), cycle_len=cl)\n",
    "    learner.save(f'{PRE}{pretrain_id}')\n",
    "    learner.save_encoder(f'{PRE}{pretrain_id}_enc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
